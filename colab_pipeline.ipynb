{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-Learning Analysis of Smartphone and Electronic-Stethoscope Phonocardiograms for Detection of Reduced Left Ventricular Ejection Fraction\n",
    "\n",
    "This notebook rebuilds derived artifacts and runs experiments on Google Colab.\n",
    "This version runs directly from Google Drive (drive-only) to avoid long copy steps.\n",
    "Outputs are written to `/content/pcg_runs` and synced back to Drive in the final step.\n",
    "\n",
    "No deep-learning background is required: follow the steps in order and keep defaults unless you have a reason to change them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glossary (Quick)\n- Representation: MFCC or gammatone spectrogram input\n- Backbone: ImageNet-pretrained model (e.g., MobileNetV2, SwinV2)\n- Normalization: standardize spectrograms (single-set or per-device)\n- CV (5-fold): train 5 times on different splits, average results\n- Checkpoint: saved model weights (`best.pth`)\n- Eval-only: evaluate a saved checkpoint without retraining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 \u2014 Mount Google Drive\n",
    "Set `DRIVE_REPO_DIR` to the folder containing this repo and your data.\n",
    "This workflow runs code/data directly from Drive (no local copy).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def rsync(src, dst, excludes=None, delete=False):\n",
    "    cmd = ['rsync', '-a']\n",
    "    if delete:\n",
    "        cmd.append('--delete')\n",
    "    if excludes:\n",
    "        for ex in excludes:\n",
    "            cmd += ['--exclude', ex]\n",
    "    cmd += [src, dst]\n",
    "    print(' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "def run_command(cmd):\n",
    "    env = {**os.environ, 'PYTHONUNBUFFERED': '1'}\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    proc = subprocess.Popen(\n",
    "        cmd,\n",
    "        env=env,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1,\n",
    "    )\n",
    "    for line in proc.stdout:\n",
    "        print(line, end='')\n",
    "    returncode = proc.wait()\n",
    "    if returncode != 0:\n",
    "        raise subprocess.CalledProcessError(returncode, cmd)\n",
    "\n",
    "DRIVE_REPO_DIR = '/content/drive/MyDrive/phonocardiogram-lvef-deeplearning'\n",
    "WORK_DIR = DRIVE_REPO_DIR  # drive-only workflow\n",
    "HEART_DIR = f\"{DRIVE_REPO_DIR}/heart_sounds\"\n",
    "LVEF_CSV = f\"{DRIVE_REPO_DIR}/lvef.csv\"\n",
    "RUNS_DIR = '/content/pcg_runs'\n",
    "\n",
    "SYNC_BACK_TO_DRIVE = True\n",
    "SYNC_DELETE = False  # set True to mirror local runs to Drive (deletes Drive-only files)\n",
    "DRIVE_RUNS_DIR = f\"{DRIVE_REPO_DIR}/runs\"\n",
    "\n",
    "if not os.path.exists(LVEF_CSV):\n",
    "    raise FileNotFoundError(f'Missing LVEF CSV: {LVEF_CSV}')\n",
    "if not os.path.isdir(HEART_DIR):\n",
    "    raise FileNotFoundError(f'Missing heart_sounds dir: {HEART_DIR}')\n",
    "\n",
    "os.makedirs(RUNS_DIR, exist_ok=True)\n",
    "os.chdir(WORK_DIR)\n",
    "print('WORK_DIR:', WORK_DIR)\n",
    "print('LVEF_CSV:', LVEF_CSV)\n",
    "print('HEART_DIR:', HEART_DIR)\n",
    "print('RUNS_DIR:', RUNS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - Restore Summary Only from Drive\n",
    "If you only need the aggregated table, this restores `summary.csv` without copying all runs.\n",
    "Note: this does not restore checkpoints or per-run metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shutil\n",
    "\n",
    "RESTORE_SUMMARY_FROM_DRIVE = True  # set False to start fresh\n",
    "\n",
    "if RESTORE_SUMMARY_FROM_DRIVE:\n",
    "    src = f\"{DRIVE_RUNS_DIR}/results/summary.csv\"\n",
    "    dst_dir = f\"{RUNS_DIR}/results\"\n",
    "    if not os.path.exists(src):\n",
    "        print(f\"No summary.csv found at {src}; skipping restore.\")\n",
    "    else:\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        dst = f\"{dst_dir}/summary.csv\"\n",
    "        shutil.copy2(src, dst)\n",
    "        print(\"Restored summary.csv to:\", dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 \u2014 Install Requirements\n",
    "Colab already provides PyTorch. This installs the remaining packages from `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "print('torch:', torch.__version__)\n",
    "print('cuda:', torch.version.cuda)\n",
    "print('cuda available:', torch.cuda.is_available())\n",
    "\n",
    "reqs = [r.strip() for r in Path('requirements.txt').read_text().splitlines() if r.strip()]\n",
    "reqs = [r for r in reqs if not r.startswith('torch') and not r.startswith('torchaudio')]\n",
    "cmd = [sys.executable, '-m', 'pip', 'install'] + reqs\n",
    "print('Installing:', ' '.join(reqs))\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the filename pattern (important)\n",
    "This workflow expects filenames like `aData2001A.wav`, where:\n",
    "- First letter = device code (`a`=android_phone, `i`=iphone, `e`=digital stethoscope)\n",
    "- Digits = patient ID\n",
    "- Last letter = auscultation position (A/P/M/T)\n",
    "\n",
    "If your naming differs, edit `FILENAME_RE` and `DEVICE_MAP` in `src/data/build_metadata.py` before running the next cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 \u2014 Build Metadata\n",
    "Creates `metadata.csv` by linking each WAV to patient ID, device, position, and label.\n",
    "Only rerun if your raw data, labels, or filename rules changed.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m src.data.build_metadata \\\n",
    "  --lvef_csv {LVEF_CSV} \\\n",
    "  --heart_dir {HEART_DIR} \\\n",
    "  --output_csv metadata.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 \u2014 Create Patient-Level Splits\n",
    "Creates train/val/test splits and 5-fold CV splits (no patient leakage).\n",
    "Only rerun if metadata or split settings (folds/seed/val_size) changed.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m src.data.make_patient_splits \\\n",
    "  --metadata_csv metadata.csv \\\n",
    "  --output_dir splits\n",
    "\n",
    "!python -m src.data.make_patient_cv_splits \\\n",
    "  --metadata_csv metadata.csv \\\n",
    "  --output_dir splits/cv \\\n",
    "  --n_splits 5 \\\n",
    "  --n_repeats 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional \u2014 QA Report\n",
    "Use this to summarize data quality and optionally estimate a simple SNR proxy.\n",
    "Use `--max_files` to sample a subset for faster runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optional QA report (uncomment to run)\n",
    "# !mkdir -p reports\n",
    "# !python -m src.data.qa_report \\\n",
    "#   --metadata_csv metadata.csv \\\n",
    "#   --output_json reports/qa_report.json \\\n",
    "#   --output_csv reports/qa_records.csv \\\n",
    "#   --fixed_duration 4.0 \\\n",
    "#   --compute_snr \\\n",
    "#   --max_files 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 \u2014 5-Fold CV (Model Selection)\n",
    "Edit `REPRESENTATION`, `BACKBONE`, and device filters, then run this cell.\n",
    "This step trains 5 folds and summarizes results; use it to pick the best config.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input size note**\n",
    "- Use 224x224 for MobileNet and EfficientNet-B0.\n",
    "- Use 256x256 for SwinV2-Tiny/Small.\n",
    "- Use 384x384 for EfficientNetV2-S.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Only These Variables (Step 4)\n",
    "- Set the values below only; keep the rest unchanged.\n",
    "- `REPRESENTATION`: `mfcc` or `gammatone`\n",
    "- `BACKBONE`: `mobilenetv2`, `mobilenetv3_large`, `efficientnet_b0`, `efficientnetv2_s`, `swinv2_tiny`, `swinv2_small`\n",
    "- Device labels (must match metadata): `iphone`, `android_phone`, `digital_stethoscope`\n",
    "- For within-device CV, set `TRAIN_DEVICES`, `VAL_DEVICES`, `TEST_DEVICES` to the same single-device list.\n",
    "- For pooled CV, leave those three variables as `None`.\n",
    "- `IMAGE_SIZE` is set automatically from `BACKBONE` in this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Default: 5-fold CV for model selection\n",
    "REPRESENTATION = 'mfcc'  # change to 'gammatone' to compare\n",
    "BACKBONE = 'mobilenetv2'  # change to another backbone to compare\n",
    "TRAIN_DEVICES = None  # set e.g. ['iphone'] for within-device CV; leave None for pooled\n",
    "VAL_DEVICES = None  # set equal to TRAIN_DEVICES for within-device CV\n",
    "TEST_DEVICES = None  # set equal to TRAIN_DEVICES for within-device CV\n",
    "    NORMALIZATION = 'global'  # single-set stats over the chosen subset\n",
    "\n",
    "if BACKBONE.startswith('swinv2'):\n",
    "    IMAGE_SIZE = 256\n",
    "elif BACKBONE == 'efficientnetv2_s':\n",
    "    IMAGE_SIZE = 384\n",
    "else:\n",
    "    IMAGE_SIZE = 224\n",
    "\n",
    "RUN_TAG = '-'.join(TRAIN_DEVICES) if TRAIN_DEVICES else 'pooled'  # used to label CV runs\n",
    "RUN_NAME_FORMAT = f\"cv_{RUN_TAG}_im{IMAGE_SIZE}_r{{repeat:02d}}_f{{fold:02d}}_{{backbone}}_{{representation}}\"\n",
    "\n",
    "AUTO_POS_WEIGHT = True\n",
    "TUNE_THRESHOLD = True\n",
    "AMP = True\n",
    "\n",
    "import sys\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    '-m',\n",
    "    'src.experiments.run_cv',\n",
    "    '--cv_index',\n",
    "    'splits/cv/index.csv',\n",
    "    '--results_dir',\n",
    "    f'{RUNS_DIR}/results',\n",
    "    '--output_dir',\n",
    "    f'{RUNS_DIR}/checkpoints',\n",
    "    '--run_name_format',\n",
    "    RUN_NAME_FORMAT,\n",
    "    '--',\n",
    "    '--representation',\n",
    "    REPRESENTATION,\n",
    "    '--backbone',\n",
    "    BACKBONE,\n",
    "    '--normalization',\n",
    "    NORMALIZATION,\n",
    "    '--image_size',\n",
    "    str(IMAGE_SIZE),\n",
    "]\n",
    "\n",
    "if AUTO_POS_WEIGHT:\n",
    "    cmd.append('--auto_pos_weight')\n",
    "if TUNE_THRESHOLD:\n",
    "    cmd.append('--tune_threshold')\n",
    "if AMP:\n",
    "    cmd.append('--amp')\n",
    "\n",
    "if TRAIN_DEVICES:\n",
    "    cmd += ['--train_device_filter', *TRAIN_DEVICES]\n",
    "if VAL_DEVICES:\n",
    "    cmd += ['--val_device_filter', *VAL_DEVICES]\n",
    "if TEST_DEVICES:\n",
    "    cmd += ['--test_device_filter', *TEST_DEVICES]\n",
    "\n",
    "run_command(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional \u2014 TF Stats (for non-CV runs)\nSet `RUN_TF_STATS=True` only if you plan to train without CV (e.g., final within-device checkpoints).\nThese stats are computed from the training split only (no val/test patients). The default is a single set of stats over whatever subset you select.\nIf you want device-only stats for a within-device final checkpoint, add a device filter and match the image size to your backbone.\n\nBackbone image size reminder: SwinV2 = 256, EfficientNetV2-S = 384, everything else = 224.\n\nExample (android_phone, gammatone, SwinV2-Tiny):\n```bash\npython -m src.data.compute_stats \\\n  --train_csv splits/metadata_train.csv \\\n  --representations gammatone \\\n  --device_filter android_phone \\\n  --image_size 256\n```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "RUN_TF_STATS = False  # set True for non-CV training (final within-device or pooled)\n",
    "\n",
    "# Example: if your best config is android_phone + gammatone + swinv2_tiny,\n",
    "# use --device_filter android_phone and --image_size 256.\n",
    "# For efficientnetv2_s, use --image_size 384. Otherwise, use 224.\n",
    "# Tip: add --output_json tf_stats_<device>.json to keep per-device files.\n",
    "\n",
    "if RUN_TF_STATS:\n",
    "\n",
    "    !python -m src.data.compute_stats \\\n",
    "      --train_csv splits/metadata_train.csv \\\n",
    "      --representations gammatone \\\n",
    "      --device_filter android_phone \\\n",
    "      --image_size 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips to Avoid Mistakes\n- If you change data, labels, or filename rules, rerun Step 2 and Step 3.\n- Device names must match metadata (`iphone`, `android_phone`, `digital_stethoscope`). If your labels differ (e.g., `android`), update `DEVICE_MAP` in `src/data/build_metadata.py` and rebuild metadata.\n- For cross-device eval, replace `<run_name>` with the actual checkpoint folder.\n- Do not tune anything using the test split.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 \u2014 Final Within-Device Training\nEnable this only after CV. This creates one final checkpoint per device using the chosen config.\nThis step requires `tf_stats.json` (run the Optional TF Stats step first).\n\nIf you want device-only stats for a strict within-device final model, compute stats with `--device_filter` and the correct `--image_size`.\nExample: for android_phone + gammatone + swinv2_tiny, use `--device_filter android_phone --representations gammatone --image_size 256`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Only These Variables\n- Set `RUN_SINGLE = True` when you are ready to run this step.\n- Replace the values below with one of the allowed options.\n\n**Allowed options**\n- `REPRESENTATION`: `mfcc` or `gammatone`\n- `BACKBONE`: `mobilenetv2`, `mobilenetv3_large`, `efficientnet_b0`, `efficientnetv2_s`, `swinv2_tiny`, `swinv2_small`\n- Device labels (must match metadata): `iphone`, `android_phone`, `digital_stethoscope`\n\n**Within-device rule**\n- Set `TRAIN_DEVICES`, `VAL_DEVICES`, and `TEST_DEVICES` to the same single-device list. Example: `['iphone']`.\n\n**Image size**\n- `IMAGE_SIZE` is set automatically from `BACKBONE` in this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: train a final within-device model (single run)\n",
    "RUN_SINGLE = False  # set True after you pick the best config from CV\n",
    "# Available options:\n",
    "#   REPRESENTATION: 'mfcc' | 'gammatone'\n",
    "#   BACKBONE: 'mobilenetv2' | 'mobilenetv3_large' | 'efficientnet_b0' | 'efficientnetv2_s' | 'swinv2_tiny' | 'swinv2_small'\n",
    "#   DEVICES: ['iphone'] | ['android_phone'] | ['digital_stethoscope'] (must match metadata)\n",
    "\n",
    "if RUN_SINGLE:\n",
    "    import sys\n",
    "\n",
    "    REPRESENTATION = 'mfcc'\n",
    "    BACKBONE = 'mobilenetv2'\n",
    "    TRAIN_DEVICES = None  # set to one device for within-device final model\n",
    "    VAL_DEVICES = None  # set equal to TRAIN_DEVICES for within-device\n",
    "    TEST_DEVICES = None  # set equal to TRAIN_DEVICES for within-device\n",
    "    NORMALIZATION = 'global'  # single-set stats over the chosen subset\n",
    "    if BACKBONE.startswith('swinv2'):\n",
    "        IMAGE_SIZE = 256\n",
    "    elif BACKBONE == 'efficientnetv2_s':\n",
    "        IMAGE_SIZE = 384\n",
    "    else:\n",
    "        IMAGE_SIZE = 224\n",
    "\n",
    "    if not os.path.exists('tf_stats.json'):\n",
    "        raise FileNotFoundError('tf_stats.json not found. Run the Optional TF Stats step first.')\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        '-m',\n",
    "        'src.training.train',\n",
    "        '--train_csv',\n",
    "        'splits/metadata_train.csv',\n",
    "        '--val_csv',\n",
    "        'splits/metadata_val.csv',\n",
    "        '--test_csv',\n",
    "        'splits/metadata_test.csv',\n",
    "        '--representation',\n",
    "        REPRESENTATION,\n",
    "        '--backbone',\n",
    "        BACKBONE,\n",
    "        '--normalization',\n",
    "        NORMALIZATION,\n",
    "        '--image_size',\n",
    "        str(IMAGE_SIZE),\n",
    "        '--results_dir',\n",
    "        f'{RUNS_DIR}/results',\n",
    "        '--output_dir',\n",
    "        f'{RUNS_DIR}/checkpoints',\n",
    "        '--auto_pos_weight',\n",
    "        '--tune_threshold',\n",
    "        '--amp',\n",
    "        '--per_device_eval',\n",
    "        '--save_predictions',\n",
    "        '--save_history',\n",
    "    ]\n",
    "\n",
    "    if TRAIN_DEVICES:\n",
    "        cmd += ['--train_device_filter', *TRAIN_DEVICES]\n",
    "    if VAL_DEVICES:\n",
    "        cmd += ['--val_device_filter', *VAL_DEVICES]\n",
    "    if TEST_DEVICES:\n",
    "        cmd += ['--test_device_filter', *TEST_DEVICES]\n",
    "\n",
    "    run_command(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 \u2014 Cross-Device Evaluation (No Retraining)\n",
    "Uses a saved checkpoint and evaluates on other devices. The model is not updated.\n",
    "Set `CHECKPOINT_PATH` manually to the within-device checkpoint you selected, and set `TEST_DEVICES` to the target devices you want to evaluate.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optional: cross-device evaluation from a saved checkpoint (no retraining)\n",
    "RUN_EVAL_ONLY = False\n",
    "\n",
    "if RUN_EVAL_ONLY:\n",
    "    import sys\n",
    "\n",
    "    CHECKPOINT_PATH = f'{RUNS_DIR}/checkpoints/<run_name>/best.pth'  # set manually to your chosen within-device run\n",
    "    TEST_DEVICES = ['iphone', 'digital_stethoscope']  # evaluate this checkpoint on these devices (e.g., android model -> iphone + stethoscope)\n",
    "\n",
    "    if not os.path.exists(CHECKPOINT_PATH):\n",
    "        raise FileNotFoundError(f'Checkpoint not found: {CHECKPOINT_PATH}')\n",
    "\n",
    "    # Representation/backbone/normalization are loaded from the checkpoint.\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        '-m',\n",
    "        'src.training.train',\n",
    "        '--eval_only',\n",
    "        '--checkpoint_path',\n",
    "        CHECKPOINT_PATH,\n",
    "        '--train_csv',\n",
    "        'splits/metadata_train.csv',\n",
    "        '--val_csv',\n",
    "        'splits/metadata_val.csv',\n",
    "        '--test_csv',\n",
    "        'splits/metadata_test.csv',\n",
    "        '--results_dir',\n",
    "        f'{RUNS_DIR}/results',\n",
    "        '--per_device_eval',\n",
    "        '--save_predictions',\n",
    "    ]\n",
    "\n",
    "    if TEST_DEVICES:\n",
    "        cmd += ['--test_device_filter', *TEST_DEVICES]\n",
    "\n",
    "    run_command(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs to Inspect\nAll outputs are under `RUNS_DIR` (default: `/content/pcg_runs`):\n- `RUNS_DIR/results/summary.csv`: main table of metrics per run (use this for tables)\n- `RUNS_DIR/results/selection/best_config_per_device.csv`: best config per device\n- `RUNS_DIR/results/selection/config_summary_by_device.csv`: aggregated config stats per device\n- `RUNS_DIR/results/<run_name>/predictions_test.csv`: for ROC/PR curves (final models only)\n- `RUNS_DIR/checkpoints/<run_name>/best.pth`: saved model weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 \u2014 Sync Outputs to Drive\n",
    "Copies results back to Google Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if SYNC_BACK_TO_DRIVE:\n",
    "    os.makedirs(DRIVE_RUNS_DIR, exist_ok=True)\n",
    "    rsync(RUNS_DIR + '/', DRIVE_RUNS_DIR + '/', delete=SYNC_DELETE)\n",
    "    print('Synced runs to drive:', DRIVE_RUNS_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}