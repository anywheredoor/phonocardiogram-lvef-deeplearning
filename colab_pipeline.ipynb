{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-Learning Analysis of Smartphone and Electronic-Stethoscope Phonocardiograms for Detection of Reduced Left Ventricular Ejection Fraction\n",
    "\n",
    "This notebook rebuilds all derived artifacts and runs experiments on Google Colab.\n",
    "Default settings prioritize the fastest training (local /content storage for code, data, cache, and results).\n",
    "Set `USE_LOCAL_DATA = False` if your dataset is too large for /content.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_REPO_DIR = '/content/drive/MyDrive/phonocardiogram-lvef-deeplearning'\n",
    "WORK_DIR = '/content/pcg_repo'\n",
    "DATA_DIR = '/content/pcg_data'\n",
    "RUNS_DIR = '/content/pcg_runs'\n",
    "USE_LOCAL_DATA = True  # fastest default\n",
    "SYNC_BACK_TO_DRIVE = True\n",
    "SYNC_DERIVED = True\n",
    "DRIVE_RUNS_DIR = f\"{DRIVE_REPO_DIR}/runs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "def rsync(src, dst, excludes=None):\n",
    "    cmd = ['rsync', '-a', '--delete']\n",
    "    if excludes:\n",
    "        for ex in excludes:\n",
    "            cmd += ['--exclude', ex]\n",
    "    cmd += [src, dst]\n",
    "    print(' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "rsync(DRIVE_REPO_DIR + '/', WORK_DIR + '/', excludes=['.git', 'cache', 'splits', 'results', 'checkpoints', 'checkpoints_cpu', '__pycache__'])\n",
    "\n",
    "if USE_LOCAL_DATA:\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    rsync(DRIVE_REPO_DIR + '/heart_sounds/', DATA_DIR + '/heart_sounds/')\n",
    "    shutil.copy2(DRIVE_REPO_DIR + '/lvef.csv', DATA_DIR + '/lvef.csv')\n",
    "    LVEF_CSV = f\"{DATA_DIR}/lvef.csv\"\n",
    "    HEART_DIR = f\"{DATA_DIR}/heart_sounds\"\n",
    "else:\n",
    "    LVEF_CSV = f\"{DRIVE_REPO_DIR}/lvef.csv\"\n",
    "    HEART_DIR = f\"{DRIVE_REPO_DIR}/heart_sounds\"\n",
    "\n",
    "if not os.path.exists(LVEF_CSV):\n",
    "    raise FileNotFoundError(f'Missing LVEF CSV: {LVEF_CSV}')\n",
    "if not os.path.isdir(HEART_DIR):\n",
    "    raise FileNotFoundError(f'Missing heart_sounds dir: {HEART_DIR}')\n",
    "\n",
    "os.makedirs(RUNS_DIR, exist_ok=True)\n",
    "os.chdir(WORK_DIR)\n",
    "print('WORK_DIR:', WORK_DIR)\n",
    "print('LVEF_CSV:', LVEF_CSV)\n",
    "print('HEART_DIR:', HEART_DIR)\n",
    "print('RUNS_DIR:', RUNS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "print('torch:', torch.__version__)\n",
    "print('cuda:', torch.version.cuda)\n",
    "print('cuda available:', torch.cuda.is_available())\n",
    "\n",
    "reqs = [r.strip() for r in Path('requirements.txt').read_text().splitlines() if r.strip()]\n",
    "reqs = [r for r in reqs if not r.startswith('torch') and not r.startswith('torchaudio')]\n",
    "cmd = [sys.executable, '-m', 'pip', 'install'] + reqs\n",
    "print('Installing:', ' '.join(reqs))\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your filename pattern differs, edit `FILENAME_RE` / `DEVICE_MAP` in `src/data/build_metadata.py` before running the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m src.data.build_metadata \\\n",
    "  --lvef_csv {LVEF_CSV} \\\n",
    "  --heart_dir {HEART_DIR} \\\n",
    "  --output_csv metadata.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m src.data.make_patient_splits \\\n",
    "  --metadata_csv metadata.csv \\\n",
    "  --output_dir splits\n",
    "\n",
    "!python -m src.data.make_patient_cv_splits \\\n",
    "  --metadata_csv metadata.csv \\\n",
    "  --output_dir splits/cv \\\n",
    "  --n_splits 5 \\\n",
    "  --n_repeats 1\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "PER_DEVICE_STATS = False  # set True for per-device normalization\n",
    "per_device_flag = '--per_device' if PER_DEVICE_STATS else ''\n",
    "\n",
    "!python -m src.data.compute_stats \\\n",
    "  --train_csv splits/metadata_train.csv \\\n",
    "  --representations mfcc gammatone \\\n",
    "  {per_device_flag}\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "CACHE_ROOT = '/content/pcg_cache'\n",
    "NORMALIZATION = 'per_device' if PER_DEVICE_STATS else 'global'\n",
    "\n",
    "for rep in ['mfcc', 'gammatone']:\n",
    "    print(f'Caching {rep}...')\n",
    "    !python -m src.data.precompute_cache \\\n",
    "      --representation {rep} \\\n",
    "      --normalization {NORMALIZATION} \\\n",
    "      --cache_root {CACHE_ROOT} \\\n",
    "      --splits splits/metadata_train.csv splits/metadata_val.csv splits/metadata_test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optional QA report\n",
    "# !mkdir -p reports\n",
    "# !python -m src.data.qa_report \\\n",
    "#   --metadata_csv metadata.csv \\\n",
    "#   --output_json reports/qa_report.json \\\n",
    "#   --output_csv reports/qa_records.csv \\\n",
    "#   --fixed_duration 4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Default: 5-fold CV for model selection\n",
    "REPRESENTATION = 'mfcc'\n",
    "BACKBONE = 'mobilenetv2'\n",
    "TRAIN_DEVICES = None  # e.g. ['iphone'] for within-device CV\n",
    "VAL_DEVICES = None\n",
    "TEST_DEVICES = None\n",
    "\n",
    "AUTO_POS_WEIGHT = True\n",
    "TUNE_THRESHOLD = True\n",
    "AMP = True\n",
    "USE_CACHE = False  # CV splits are on-the-fly unless you precompute cache per fold\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    '-m',\n",
    "    'src.experiments.run_cv',\n",
    "    '--cv_index',\n",
    "    'splits/cv/index.csv',\n",
    "    '--results_dir',\n",
    "    f'{RUNS_DIR}/results',\n",
    "    '--output_dir',\n",
    "    f'{RUNS_DIR}/checkpoints',\n",
    "    '--',\n",
    "    '--representation',\n",
    "    REPRESENTATION,\n",
    "    '--backbone',\n",
    "    BACKBONE,\n",
    "]\n",
    "\n",
    "if AUTO_POS_WEIGHT:\n",
    "    cmd.append('--auto_pos_weight')\n",
    "if TUNE_THRESHOLD:\n",
    "    cmd.append('--tune_threshold')\n",
    "if AMP:\n",
    "    cmd.append('--amp')\n",
    "if USE_CACHE:\n",
    "    cmd.append('--use_cache')\n",
    "\n",
    "if TRAIN_DEVICES:\n",
    "    cmd += ['--train_device_filter', *TRAIN_DEVICES]\n",
    "if VAL_DEVICES:\n",
    "    cmd += ['--val_device_filter', *VAL_DEVICES]\n",
    "if TEST_DEVICES:\n",
    "    cmd += ['--test_device_filter', *TEST_DEVICES]\n",
    "\n",
    "print('Running:', ' '.join(cmd))\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optional: train a final within-device model (single run)\n",
    "RUN_SINGLE = False\n",
    "\n",
    "if RUN_SINGLE:\n",
    "    import sys\n",
    "    import subprocess\n",
    "\n",
    "    REPRESENTATION = 'mfcc'\n",
    "    BACKBONE = 'mobilenetv2'\n",
    "    TRAIN_DEVICES = None  # e.g. ['android_phone']\n",
    "    VAL_DEVICES = None\n",
    "    TEST_DEVICES = None\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        '-m',\n",
    "        'src.training.train',\n",
    "        '--train_csv',\n",
    "        'splits/metadata_train.csv',\n",
    "        '--val_csv',\n",
    "        'splits/metadata_val.csv',\n",
    "        '--test_csv',\n",
    "        'splits/metadata_test.csv',\n",
    "        '--representation',\n",
    "        REPRESENTATION,\n",
    "        '--backbone',\n",
    "        BACKBONE,\n",
    "        '--results_dir',\n",
    "        f'{RUNS_DIR}/results',\n",
    "        '--output_dir',\n",
    "        f'{RUNS_DIR}/checkpoints',\n",
    "        '--use_cache',\n",
    "        '--auto_pos_weight',\n",
    "        '--tune_threshold',\n",
    "        '--amp',\n",
    "        '--per_device_eval',\n",
    "        '--save_predictions',\n",
    "        '--save_history',\n",
    "    ]\n",
    "\n",
    "    if TRAIN_DEVICES:\n",
    "        cmd += ['--train_device_filter', *TRAIN_DEVICES]\n",
    "    if VAL_DEVICES:\n",
    "        cmd += ['--val_device_filter', *VAL_DEVICES]\n",
    "    if TEST_DEVICES:\n",
    "        cmd += ['--test_device_filter', *TEST_DEVICES]\n",
    "\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optional: cross-device evaluation from a saved checkpoint (no retraining)\n",
    "RUN_EVAL_ONLY = False\n",
    "\n",
    "if RUN_EVAL_ONLY:\n",
    "    import sys\n",
    "    import subprocess\n",
    "\n",
    "    CHECKPOINT_PATH = f'{RUNS_DIR}/checkpoints/<run_name>/best.pth'\n",
    "    TEST_DEVICES = ['iphone', 'digital_stethoscope']\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        '-m',\n",
    "        'src.training.train',\n",
    "        '--eval_only',\n",
    "        '--checkpoint_path',\n",
    "        CHECKPOINT_PATH,\n",
    "        '--train_csv',\n",
    "        'splits/metadata_train.csv',\n",
    "        '--val_csv',\n",
    "        'splits/metadata_val.csv',\n",
    "        '--test_csv',\n",
    "        'splits/metadata_test.csv',\n",
    "        '--results_dir',\n",
    "        f'{RUNS_DIR}/results',\n",
    "        '--per_device_eval',\n",
    "        '--save_predictions',\n",
    "    ]\n",
    "\n",
    "    if TEST_DEVICES:\n",
    "        cmd += ['--test_device_filter', *TEST_DEVICES]\n",
    "\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if SYNC_DERIVED:\n",
    "    shutil.copy2('metadata.csv', f\"{DRIVE_REPO_DIR}/metadata.csv\")\n",
    "    shutil.copy2('tf_stats.json', f\"{DRIVE_REPO_DIR}/tf_stats.json\")\n",
    "    rsync('splits/', f\"{DRIVE_REPO_DIR}/splits/\")\n",
    "    print('Synced derived artifacts to drive.')\n",
    "\n",
    "if SYNC_BACK_TO_DRIVE:\n",
    "    os.makedirs(DRIVE_RUNS_DIR, exist_ok=True)\n",
    "    rsync(RUNS_DIR + '/', DRIVE_RUNS_DIR + '/')\n",
    "    print('Synced runs to drive:', DRIVE_RUNS_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}